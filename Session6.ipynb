{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd24b9c3",
   "metadata": {},
   "source": [
    "#### To create a dataset with 7 Inputs, 1 Output, including 1,000 data points.\n",
    "\n",
    "In this data set, 'Gender', 'Major', 'TypeOfSchool', 'Region', 'Grade' are categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d71400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a completely random dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "data = {\n",
    "    \"Age\": [random.randint(18, 30) for _ in range(1000)],\n",
    "    \"Gender\": [random.choice([\"Male\", \"Female\"]) for _ in range(1000)],\n",
    "    \"StudyHours\": [random.randint(5, 25) for _ in range(1000)],\n",
    "    \"Participation\": [random.randint(1, 10) for _ in range(1000)],\n",
    "    \"Major\": [random.choice([\"Computer Science\", \"Biology\", \"Business\", \"Literature\", \"Physics\"]) for _ in range(1000)],\n",
    "    \"TypeOfSchool\": [random.choice([\"Public\", \"Private\", \"Online\"]) for _ in range(1000)],\n",
    "    \"Region\": [random.choice([\"North\", \"South\", \"East\", \"West\", \"Central\"]) for _ in range(1000)],\n",
    "    \"Grade\": [random.choice([\"Pass\", \"Fail\"]) for _ in range(1000)]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"students_grades.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146120f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with stronger relationship between Inputs and Outputs\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def determine_grade(study_hours, participation, school_type):\n",
    "    # Base probability of passing\n",
    "    base_prob = 0.4  # Adjusted down to allow for larger swings based on criteria\n",
    "    \n",
    "    # Increase the probability based on study hours\n",
    "    if study_hours > 20:\n",
    "        base_prob += 0.4\n",
    "    elif study_hours > 15:\n",
    "        base_prob += 0.3\n",
    "    elif study_hours > 10:\n",
    "        base_prob += 0.2\n",
    "    elif study_hours <= 10:\n",
    "        base_prob -= 0.1\n",
    "    \n",
    "    # Increase the probability based on participation\n",
    "    if participation > 8:\n",
    "        base_prob += 0.3\n",
    "    elif participation > 6:\n",
    "        base_prob += 0.2\n",
    "    elif participation <= 5:\n",
    "        base_prob -= 0.2\n",
    "    \n",
    "    # Adjust the probability based on school type\n",
    "    if school_type == \"Private\":\n",
    "        base_prob += 0.2\n",
    "    elif school_type == \"Online\":\n",
    "        base_prob -= 0.2\n",
    "    \n",
    "    # Final decision\n",
    "    return \"Pass\" if random.random() < base_prob else \"Fail\"\n",
    "\n",
    "data = {\n",
    "    \"Age\": [random.randint(18, 30) for _ in range(1000)],\n",
    "    \"Gender\": [random.choice([\"Male\", \"Female\"]) for _ in range(1000)],\n",
    "    \"StudyHours\": [random.randint(5, 25) for _ in range(1000)],\n",
    "    \"Participation\": [random.randint(1, 10) for _ in range(1000)],\n",
    "    \"Major\": [random.choice([\"Computer Science\", \"Biology\", \"Business\", \"Literature\", \"Physics\"]) for _ in range(1000)],\n",
    "    \"TypeOfSchool\": [random.choice([\"Public\", \"Private\", \"Online\"]) for _ in range(1000)],\n",
    "    \"Region\": [random.choice([\"North\", \"South\", \"East\", \"West\", \"Central\"]) for _ in range(1000)],\n",
    "}\n",
    "data[\"Grade\"] = [determine_grade(data[\"StudyHours\"][i], data[\"Participation\"][i], data[\"TypeOfSchool\"][i]) for i in range(1000)]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"students_grades.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613ddd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c6423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"SupervisedLearning\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b6c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = spark.read.csv('students_grades.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19323ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing data by deletion\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235dc58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the type of each column\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a65a72",
   "metadata": {},
   "source": [
    "\n",
    "In machine learning, the categorial data are generall encoded before running a ML algorithm.\n",
    "\n",
    "#### What is Categorical Data?\n",
    "\n",
    "- Categorical data are variables that contain label values rather than numeric values.\n",
    "- The number of possible values is often limited to a fixed set.\n",
    "- Categorical variables are often called **Nominal**.\n",
    "\n",
    "Some examples include:\n",
    "\n",
    "A “pet” variable with the values: “dog” and “cat“.\n",
    "A “color” variable with the values: “red“, “green” and “blue“.\n",
    "A “place” variable with the values: “first”, “second” and “third“.\n",
    "\n",
    "#### What is the Problem with Categorical Data?\n",
    "- Some algorithms can work with categorical data directly.\n",
    "- Many machine learning algorithms cannot operate on label data directly. They require all input variables and output variables to be numeric.\n",
    "\n",
    "#### Solution: Convert Categorical Data to Numerical Data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3937b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list including all categorical columns of INPUTS\n",
    "categorical_cols = ['Gender', 'Major', 'TypeOfSchool', 'Region', 'Grade']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f9459f",
   "metadata": {},
   "source": [
    "#### StringIndexer:\n",
    "\n",
    "The StringIndexer is a vital PySpark feature that helps convert categorical string columns in a DataFrame into numerical indices.\n",
    "\n",
    "\n",
    "#### Pipeline:\n",
    "Pipeline is a tool from the PySpark ML library that allows for the chaining and structuring of multiple stages of data processing and/or modeling steps.\n",
    "\n",
    "`stages=indexers` means that the pipeline is being constructed with a series of stages that are represented by the indexers list. Each stage in indexers represents a StringIndexer transformation, which is used to convert categorical string columns into numeric indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63759977",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"Numeric\").fit(df) for col in categorical_cols]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df_encoded = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dataset\n",
    "df_encoded.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd52ef6",
   "metadata": {},
   "source": [
    "### VectorAssembler\n",
    "\n",
    "VectorAssembler is a transformer in PySpark's MLlib that combines a given list of columns into a **single vector** column. It is commonly used in the preprocessing stages of a machine learning pipeline to bring together features into one aggregate column, which is often a requirement for ML algorithms in Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d19363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns and assemble them as a vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['Age', 'GenderNumeric', 'StudyHours', 'Participation', 'MajorNumeric', 'TypeOfSchoolNumeric', 'RegionNumeric'],\n",
    "    outputCol='features')\n",
    "\n",
    "df_assembled = assembler.transform(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb91194",
   "metadata": {},
   "source": [
    "Now, all Inputs(features) have been assembled into a single vector, titled as 'features'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed2b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembled.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ccaa99",
   "metadata": {},
   "source": [
    "From this point forward, we just need two columns:\n",
    "1. **features** which includes all Inputs\n",
    "2. **GradeNumeric** which is the Output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the Input and Output columns into a new dataframe\n",
    "df_assembled_filtered = df_assembled.select(\"features\", \"GradeNumeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f099971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembled_filtered.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d6d33a",
   "metadata": {},
   "source": [
    "### Building the MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d875cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "train_data, test_data = df_assembled_filtered.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06137512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Decision Tree model\n",
    "dtc = DecisionTreeClassifier(featuresCol='features', labelCol=\"GradeNumeric\")\n",
    "model = dtc.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cfd503",
   "metadata": {},
   "source": [
    "### Prediction using the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions using test_data\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Raw prediction\" for each possible label. The meaning of a \"raw\" prediction may vary between algorithms, but it intuitively gives a measure of confidence in each possible label (where larger = more confident).\n",
    "predictions.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52dddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Decision Tree rules\n",
    "print(model.toDebugString)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15376414",
   "metadata": {},
   "source": [
    "### Evaluate the performance of a binary classification model\n",
    "\n",
    "**BinaryClassificationEvaluator:** This is an evaluator for binary classification, which expects two input columns: **raw prediction** and **label**.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "`rawPredictionCol=\"rawPrediction\"`: This parameter tells the evaluator to expect the column named \"rawPrediction\" in the dataset (typically predictions in this context) to hold the raw prediction values from the model.\n",
    "`labelCol=\"GradeNumeric\"`: This parameter tells the evaluator that the true labels for the binary classification task can be found in the \"GradeNumeric\" column of the dataset.\n",
    "evaluate() Method:\n",
    "\n",
    "`evaluator.evaluate(predictions)`: This is where the actual evaluation happens. The evaluate() method computes the metric (Area Under ROC, by default) for the predictions dataset using the true labels and raw predictions.\n",
    "\n",
    "**Area Under ROC:**\n",
    "\n",
    "The code calculates the Area Under the Receiver Operating Characteristic (ROC) curve, which is a metric used to evaluate the performance of binary classification models. The value of Area Under ROC (often abbreviated as AUC) ranges between 0 and 1. A value of 0.5 indicates no discriminative power (i.e., the model is as good as random guessing), while a value of 1.0 indicates perfect classification. A higher AUC indicates a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"GradeNumeric\")\n",
    "area_under_roc = evaluator.evaluate(predictions)\n",
    "print(\"Area Under ROC:\", area_under_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436e1e14",
   "metadata": {},
   "source": [
    "When dealing with Spark's Machine Learning Library (MLlib), often one needs to evaluate the performance of a model, especially for classification tasks. In order to do that, you often use evaluators that require the prediction and actual label in a specific format.\n",
    "\n",
    "Convert 'predictions' DataFrame to an **Resilient Distributed Dataset(RDD)** of (prediction, label) tuples\" means that you need to transform the DataFrame (predictions) which contains predicted and actual values into a Resilient Distributed Dataset (RDD) that consists of tuples. Each tuple in this RDD contains two elements: the **predicted value** (often the first element) and the **actual label** (often the second element).\n",
    "\n",
    "Each tuple in this RDD contains two elements: the predicted value (often the first element) and the actual label (often the second element).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f331d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convert 'predictions' DataFrame to an RDD of (prediction, label) tuples\n",
    "\n",
    "prediction_and_label = predictions.select(\"prediction\", \"GradeNumeric\").rdd.map(lambda row: (float(row[\"prediction\"]), float(row[\"GradeNumeric\"])))\n",
    "prediction_and_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e67d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 'collect' to show the content of a RDD\n",
    "for pred, label in prediction_and_label.collect():\n",
    "    print(f\"Prediction: {pred}, Actual Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c45aad",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Where:\n",
    "\n",
    "- **TN (True Negative):** The number of actual negatives (0s) that were correctly predicted as negatives by the model.\n",
    "- **FP (False Positive):** The number of actual negatives (0s) that were incorrectly predicted as positives (1s) by the model.\n",
    "- **FN (False Negative):** The number of actual positives (1s) that were incorrectly predicted as negatives (0s) by the model.\n",
    "- **TP (True Positive):** The number of actual positives (1s) that were correctly predicted as positives by the model.\n",
    "\n",
    "\n",
    "###### Interpretation:\n",
    "\n",
    "**High values of TP and TN, along with low values of FP and FN, generally indicate a good model.**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6d8629e",
   "metadata": {},
   "source": [
    "          Predicted: \n",
    "          0     |   1\n",
    "-----------------------\n",
    "Actual: 0 |  TN    |   FP \n",
    "-----------------------\n",
    "Actual: 1 |  FN    |   TP \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb8a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MulticlassMetrics object to develop the Confusion Matrix\n",
    "metrics = MulticlassMetrics(prediction_and_label)\n",
    "confusion_matrix = metrics.confusionMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc9b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 17:Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e7a700",
   "metadata": {},
   "source": [
    "### Using Scikit-learn package to get a detailed classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'predictions' DataFrame to a Pandas DataFrame\n",
    "predictions_pd = predictions.select(\"prediction\", \"GradeNumeric\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 19: Calculate classification report\n",
    "report = classification_report(predictions_pd[\"GradeNumeric\"], predictions_pd[\"prediction\"])\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7078b68c",
   "metadata": {},
   "source": [
    "#### Plesae investigate the meaning of these metrics, as your homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcf0628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
