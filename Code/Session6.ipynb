{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd24b9c3",
   "metadata": {},
   "source": [
    "#### To create a dataset with 7 Inputs, 1 Output, including 1,000 data points.\n",
    "\n",
    "In this data set, 'Gender', 'Major', 'TypeOfSchool', 'Region', 'Grade' are categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d71400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a completely random dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "data = {\n",
    "    \"Age\": [random.randint(18, 30) for _ in range(1000)],\n",
    "    \"Gender\": [random.choice([\"Male\", \"Female\"]) for _ in range(1000)],\n",
    "    \"StudyHours\": [random.randint(5, 25) for _ in range(1000)],\n",
    "    \"Participation\": [random.randint(1, 10) for _ in range(1000)],\n",
    "    \"Major\": [random.choice([\"Computer Science\", \"Biology\", \"Business\", \"Literature\", \"Physics\"]) for _ in range(1000)],\n",
    "    \"TypeOfSchool\": [random.choice([\"Public\", \"Private\", \"Online\"]) for _ in range(1000)],\n",
    "    \"Region\": [random.choice([\"North\", \"South\", \"East\", \"West\", \"Central\"]) for _ in range(1000)],\n",
    "    \"Grade\": [random.choice([\"Pass\", \"Fail\"]) for _ in range(1000)]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"students_grades.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "146120f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with stronger relationship between Inputs and Outputs\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def determine_grade(study_hours, participation, school_type):\n",
    "    # Base probability of passing\n",
    "    base_prob = 0.4  # Adjusted down to allow for larger swings based on criteria\n",
    "    \n",
    "    # Increase the probability based on study hours\n",
    "    if study_hours > 20:\n",
    "        base_prob += 0.4\n",
    "    elif study_hours > 15:\n",
    "        base_prob += 0.3\n",
    "    elif study_hours > 10:\n",
    "        base_prob += 0.2\n",
    "    elif study_hours <= 10:\n",
    "        base_prob -= 0.1\n",
    "    \n",
    "    # Increase the probability based on participation\n",
    "    if participation > 8:\n",
    "        base_prob += 0.3\n",
    "    elif participation > 6:\n",
    "        base_prob += 0.2\n",
    "    elif participation <= 5:\n",
    "        base_prob -= 0.2\n",
    "    \n",
    "    # Adjust the probability based on school type\n",
    "    if school_type == \"Private\":\n",
    "        base_prob += 0.2\n",
    "    elif school_type == \"Online\":\n",
    "        base_prob -= 0.2\n",
    "    \n",
    "    # Final decision\n",
    "    return \"Pass\" if random.random() < base_prob else \"Fail\"\n",
    "\n",
    "data = {\n",
    "    \"Age\": [random.randint(18, 30) for _ in range(1000)],\n",
    "    \"Gender\": [random.choice([\"Male\", \"Female\"]) for _ in range(1000)],\n",
    "    \"StudyHours\": [random.randint(5, 25) for _ in range(1000)],\n",
    "    \"Participation\": [random.randint(1, 10) for _ in range(1000)],\n",
    "    \"Major\": [random.choice([\"Computer Science\", \"Biology\", \"Business\", \"Literature\", \"Physics\"]) for _ in range(1000)],\n",
    "    \"TypeOfSchool\": [random.choice([\"Public\", \"Private\", \"Online\"]) for _ in range(1000)],\n",
    "    \"Region\": [random.choice([\"North\", \"South\", \"East\", \"West\", \"Central\"]) for _ in range(1000)],\n",
    "}\n",
    "data[\"Grade\"] = [determine_grade(data[\"StudyHours\"][i], data[\"Participation\"][i], data[\"TypeOfSchool\"][i]) for i in range(1000)]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"students_grades.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "613ddd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "036c6423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"SupervisedLearning\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b37b6c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = spark.read.csv('students_grades.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19323ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing data by deletion\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "235dc58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- StudyHours: integer (nullable = true)\n",
      " |-- Participation: integer (nullable = true)\n",
      " |-- Major: string (nullable = true)\n",
      " |-- TypeOfSchool: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Grade: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing the type of each column\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a65a72",
   "metadata": {},
   "source": [
    "\n",
    "In machine learning, the categorial data are generall encoded before running a ML algorithm.\n",
    "\n",
    "#### What is Categorical Data?\n",
    "\n",
    "- Categorical data are variables that contain label values rather than numeric values.\n",
    "- The number of possible values is often limited to a fixed set.\n",
    "- Categorical variables are often called **Nominal**.\n",
    "\n",
    "Some examples include:\n",
    "\n",
    "A “pet” variable with the values: “dog” and “cat“.\n",
    "A “color” variable with the values: “red“, “green” and “blue“.\n",
    "A “place” variable with the values: “first”, “second” and “third“.\n",
    "\n",
    "#### What is the Problem with Categorical Data?\n",
    "- Some algorithms can work with categorical data directly.\n",
    "- Many machine learning algorithms cannot operate on label data directly. They require all input variables and output variables to be numeric.\n",
    "\n",
    "#### Solution: Convert Categorical Data to Numerical Data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d3937b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list including all categorical columns of INPUTS\n",
    "categorical_cols = ['Gender', 'Major', 'TypeOfSchool', 'Region', 'Grade']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f9459f",
   "metadata": {},
   "source": [
    "#### StringIndexer:\n",
    "\n",
    "The StringIndexer is a vital PySpark feature that helps convert categorical string columns in a DataFrame into numerical indices.\n",
    "\n",
    "\n",
    "#### Pipeline:\n",
    "Pipeline is a tool from the PySpark ML library that allows for the chaining and structuring of multiple stages of data processing and/or modeling steps.\n",
    "\n",
    "`stages=indexers` means that the pipeline is being constructed with a series of stages that are represented by the indexers list. Each stage in indexers represents a StringIndexer transformation, which is used to convert categorical string columns into numeric indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63759977",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"Numeric\").fit(df) for col in categorical_cols]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df_encoded = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7286842f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Major</th>\n",
       "      <th>TypeOfSchool</th>\n",
       "      <th>Region</th>\n",
       "      <th>Grade</th>\n",
       "      <th>GenderNumeric</th>\n",
       "      <th>MajorNumeric</th>\n",
       "      <th>TypeOfSchoolNumeric</th>\n",
       "      <th>RegionNumeric</th>\n",
       "      <th>GradeNumeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Private</td>\n",
       "      <td>East</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>Business</td>\n",
       "      <td>Private</td>\n",
       "      <td>Central</td>\n",
       "      <td>Fail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Public</td>\n",
       "      <td>East</td>\n",
       "      <td>Fail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Public</td>\n",
       "      <td>West</td>\n",
       "      <td>Fail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Literature</td>\n",
       "      <td>Public</td>\n",
       "      <td>North</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Public</td>\n",
       "      <td>East</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>Literature</td>\n",
       "      <td>Public</td>\n",
       "      <td>Central</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>Business</td>\n",
       "      <td>Public</td>\n",
       "      <td>North</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Public</td>\n",
       "      <td>East</td>\n",
       "      <td>Fail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Public</td>\n",
       "      <td>Central</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender  StudyHours  Participation             Major TypeOfSchool  \\\n",
       "0     22    Male          16              8  Computer Science      Private   \n",
       "1     19    Male          12              4          Business      Private   \n",
       "2     28    Male          10              8           Biology       Public   \n",
       "3     19    Male           9              1           Physics       Public   \n",
       "4     30  Female          16              1        Literature       Public   \n",
       "..   ...     ...         ...            ...               ...          ...   \n",
       "995   19    Male          12              8  Computer Science       Public   \n",
       "996   24  Female          13              8        Literature       Public   \n",
       "997   20  Female          25              7          Business       Public   \n",
       "998   22  Female           7              4  Computer Science       Public   \n",
       "999   28  Female          19              8           Biology       Public   \n",
       "\n",
       "      Region Grade  GenderNumeric  MajorNumeric  TypeOfSchoolNumeric  \\\n",
       "0       East  Pass            1.0           4.0                  2.0   \n",
       "1    Central  Fail            1.0           2.0                  2.0   \n",
       "2       East  Fail            1.0           1.0                  1.0   \n",
       "3       West  Fail            1.0           3.0                  1.0   \n",
       "4      North  Pass            0.0           0.0                  1.0   \n",
       "..       ...   ...            ...           ...                  ...   \n",
       "995     East  Pass            1.0           4.0                  1.0   \n",
       "996  Central  Pass            0.0           0.0                  1.0   \n",
       "997    North  Pass            0.0           2.0                  1.0   \n",
       "998     East  Fail            0.0           4.0                  1.0   \n",
       "999  Central  Pass            0.0           1.0                  1.0   \n",
       "\n",
       "     RegionNumeric  GradeNumeric  \n",
       "0              1.0           0.0  \n",
       "1              3.0           1.0  \n",
       "2              1.0           1.0  \n",
       "3              2.0           1.0  \n",
       "4              0.0           0.0  \n",
       "..             ...           ...  \n",
       "995            1.0           0.0  \n",
       "996            3.0           0.0  \n",
       "997            0.0           0.0  \n",
       "998            1.0           1.0  \n",
       "999            3.0           0.0  \n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the dataset\n",
    "df_encoded.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd52ef6",
   "metadata": {},
   "source": [
    "### VectorAssembler\n",
    "\n",
    "VectorAssembler is a transformer in PySpark's MLlib that combines a given list of columns into a **single vector** column. It is commonly used in the preprocessing stages of a machine learning pipeline to bring together features into one aggregate column, which is often a requirement for ML algorithms in Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11d19363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns and assemble them as a vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['Age', 'GenderNumeric', 'StudyHours', 'Participation', 'MajorNumeric', 'TypeOfSchoolNumeric', 'RegionNumeric'],\n",
    "    outputCol='features')\n",
    "\n",
    "df_assembled = assembler.transform(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb91194",
   "metadata": {},
   "source": [
    "Now, all Inputs(features) have been assembled into a single vector, titled as 'features'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ed2b983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>StudyHours</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Major</th>\n",
       "      <th>TypeOfSchool</th>\n",
       "      <th>Region</th>\n",
       "      <th>Grade</th>\n",
       "      <th>GenderNumeric</th>\n",
       "      <th>MajorNumeric</th>\n",
       "      <th>TypeOfSchoolNumeric</th>\n",
       "      <th>RegionNumeric</th>\n",
       "      <th>GradeNumeric</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Private</td>\n",
       "      <td>East</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[22.0, 1.0, 16.0, 8.0, 4.0, 2.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>Business</td>\n",
       "      <td>Private</td>\n",
       "      <td>Central</td>\n",
       "      <td>Fail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[19.0, 1.0, 12.0, 4.0, 2.0, 2.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Public</td>\n",
       "      <td>East</td>\n",
       "      <td>Fail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[28.0, 1.0, 10.0, 8.0, 1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Public</td>\n",
       "      <td>West</td>\n",
       "      <td>Fail</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[19.0, 1.0, 9.0, 1.0, 3.0, 1.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Literature</td>\n",
       "      <td>Public</td>\n",
       "      <td>North</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[30.0, 0.0, 16.0, 1.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Public</td>\n",
       "      <td>East</td>\n",
       "      <td>Pass</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[19.0, 1.0, 12.0, 8.0, 4.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>Literature</td>\n",
       "      <td>Public</td>\n",
       "      <td>Central</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[24.0, 0.0, 13.0, 8.0, 0.0, 1.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>Business</td>\n",
       "      <td>Public</td>\n",
       "      <td>North</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[20.0, 0.0, 25.0, 7.0, 2.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Public</td>\n",
       "      <td>East</td>\n",
       "      <td>Fail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[22.0, 0.0, 7.0, 4.0, 4.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Public</td>\n",
       "      <td>Central</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[28.0, 0.0, 19.0, 8.0, 1.0, 1.0, 3.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender  StudyHours  Participation             Major TypeOfSchool  \\\n",
       "0     22    Male          16              8  Computer Science      Private   \n",
       "1     19    Male          12              4          Business      Private   \n",
       "2     28    Male          10              8           Biology       Public   \n",
       "3     19    Male           9              1           Physics       Public   \n",
       "4     30  Female          16              1        Literature       Public   \n",
       "..   ...     ...         ...            ...               ...          ...   \n",
       "995   19    Male          12              8  Computer Science       Public   \n",
       "996   24  Female          13              8        Literature       Public   \n",
       "997   20  Female          25              7          Business       Public   \n",
       "998   22  Female           7              4  Computer Science       Public   \n",
       "999   28  Female          19              8           Biology       Public   \n",
       "\n",
       "      Region Grade  GenderNumeric  MajorNumeric  TypeOfSchoolNumeric  \\\n",
       "0       East  Pass            1.0           4.0                  2.0   \n",
       "1    Central  Fail            1.0           2.0                  2.0   \n",
       "2       East  Fail            1.0           1.0                  1.0   \n",
       "3       West  Fail            1.0           3.0                  1.0   \n",
       "4      North  Pass            0.0           0.0                  1.0   \n",
       "..       ...   ...            ...           ...                  ...   \n",
       "995     East  Pass            1.0           4.0                  1.0   \n",
       "996  Central  Pass            0.0           0.0                  1.0   \n",
       "997    North  Pass            0.0           2.0                  1.0   \n",
       "998     East  Fail            0.0           4.0                  1.0   \n",
       "999  Central  Pass            0.0           1.0                  1.0   \n",
       "\n",
       "     RegionNumeric  GradeNumeric                               features  \n",
       "0              1.0           0.0  [22.0, 1.0, 16.0, 8.0, 4.0, 2.0, 1.0]  \n",
       "1              3.0           1.0  [19.0, 1.0, 12.0, 4.0, 2.0, 2.0, 3.0]  \n",
       "2              1.0           1.0  [28.0, 1.0, 10.0, 8.0, 1.0, 1.0, 1.0]  \n",
       "3              2.0           1.0   [19.0, 1.0, 9.0, 1.0, 3.0, 1.0, 2.0]  \n",
       "4              0.0           0.0  [30.0, 0.0, 16.0, 1.0, 0.0, 1.0, 0.0]  \n",
       "..             ...           ...                                    ...  \n",
       "995            1.0           0.0  [19.0, 1.0, 12.0, 8.0, 4.0, 1.0, 1.0]  \n",
       "996            3.0           0.0  [24.0, 0.0, 13.0, 8.0, 0.0, 1.0, 3.0]  \n",
       "997            0.0           0.0  [20.0, 0.0, 25.0, 7.0, 2.0, 1.0, 0.0]  \n",
       "998            1.0           1.0   [22.0, 0.0, 7.0, 4.0, 4.0, 1.0, 1.0]  \n",
       "999            3.0           0.0  [28.0, 0.0, 19.0, 8.0, 1.0, 1.0, 3.0]  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_assembled.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ccaa99",
   "metadata": {},
   "source": [
    "From this point forward, we just need two columns:\n",
    "1. **features** which includes all Inputs\n",
    "2. **GradeNumeric** which is the Output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d859ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the Input and Output columns into a new dataframe\n",
    "df_assembled_filtered = df_assembled.select(\"features\", \"GradeNumeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f099971e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>GradeNumeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[22.0, 1.0, 16.0, 8.0, 4.0, 2.0, 1.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[19.0, 1.0, 12.0, 4.0, 2.0, 2.0, 3.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[28.0, 1.0, 10.0, 8.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[19.0, 1.0, 9.0, 1.0, 3.0, 1.0, 2.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[30.0, 0.0, 16.0, 1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[19.0, 1.0, 12.0, 8.0, 4.0, 1.0, 1.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[24.0, 0.0, 13.0, 8.0, 0.0, 1.0, 3.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[20.0, 0.0, 25.0, 7.0, 2.0, 1.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[22.0, 0.0, 7.0, 4.0, 4.0, 1.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[28.0, 0.0, 19.0, 8.0, 1.0, 1.0, 3.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  features  GradeNumeric\n",
       "0    [22.0, 1.0, 16.0, 8.0, 4.0, 2.0, 1.0]           0.0\n",
       "1    [19.0, 1.0, 12.0, 4.0, 2.0, 2.0, 3.0]           1.0\n",
       "2    [28.0, 1.0, 10.0, 8.0, 1.0, 1.0, 1.0]           1.0\n",
       "3     [19.0, 1.0, 9.0, 1.0, 3.0, 1.0, 2.0]           1.0\n",
       "4    [30.0, 0.0, 16.0, 1.0, 0.0, 1.0, 0.0]           0.0\n",
       "..                                     ...           ...\n",
       "995  [19.0, 1.0, 12.0, 8.0, 4.0, 1.0, 1.0]           0.0\n",
       "996  [24.0, 0.0, 13.0, 8.0, 0.0, 1.0, 3.0]           0.0\n",
       "997  [20.0, 0.0, 25.0, 7.0, 2.0, 1.0, 0.0]           0.0\n",
       "998   [22.0, 0.0, 7.0, 4.0, 4.0, 1.0, 1.0]           1.0\n",
       "999  [28.0, 0.0, 19.0, 8.0, 1.0, 1.0, 3.0]           0.0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_assembled_filtered.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d6d33a",
   "metadata": {},
   "source": [
    "### Building the MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d875cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "train_data, test_data = df_assembled_filtered.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06137512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Decision Tree model\n",
    "dtc = DecisionTreeClassifier(featuresCol='features', labelCol=\"GradeNumeric\")\n",
    "model = dtc.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cfd503",
   "metadata": {},
   "source": [
    "### Prediction using the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6d2372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions using test_data\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "909e000c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>GradeNumeric</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[18.0, 0.0, 10.0, 5.0, 0.0, 1.0, 2.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 69.0]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[18.0, 0.0, 10.0, 9.0, 1.0, 2.0, 3.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[24.0, 11.0]</td>\n",
       "      <td>[0.6857142857142857, 0.3142857142857143]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[18.0, 0.0, 12.0, 1.0, 1.0, 2.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[58.0, 19.0]</td>\n",
       "      <td>[0.7532467532467533, 0.24675324675324675]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[18.0, 0.0, 16.0, 9.0, 0.0, 2.0, 2.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[142.0, 2.0]</td>\n",
       "      <td>[0.9861111111111112, 0.013888888888888888]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[18.0, 0.0, 17.0, 5.0, 4.0, 0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[23.0, 76.0]</td>\n",
       "      <td>[0.23232323232323232, 0.7676767676767676]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>[30.0, 1.0, 10.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 18.0]</td>\n",
       "      <td>[0.05263157894736842, 0.9473684210526315]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>[30.0, 1.0, 12.0, 3.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[23.0, 76.0]</td>\n",
       "      <td>[0.23232323232323232, 0.7676767676767676]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>[30.0, 1.0, 15.0, 3.0, 0.0, 1.0, 2.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[23.0, 76.0]</td>\n",
       "      <td>[0.23232323232323232, 0.7676767676767676]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[30.0, 1.0, 22.0, 8.0, 4.0, 2.0, 1.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[142.0, 2.0]</td>\n",
       "      <td>[0.9861111111111112, 0.013888888888888888]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[30.0, 1.0, 24.0, 3.0, 4.0, 0.0, 0.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[33.0, 25.0]</td>\n",
       "      <td>[0.5689655172413793, 0.43103448275862066]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  features  GradeNumeric rawPrediction  \\\n",
       "0    [18.0, 0.0, 10.0, 5.0, 0.0, 1.0, 2.0]           1.0   [0.0, 69.0]   \n",
       "1    [18.0, 0.0, 10.0, 9.0, 1.0, 2.0, 3.0]           1.0  [24.0, 11.0]   \n",
       "2    [18.0, 0.0, 12.0, 1.0, 1.0, 2.0, 0.0]           0.0  [58.0, 19.0]   \n",
       "3    [18.0, 0.0, 16.0, 9.0, 0.0, 2.0, 2.0]           0.0  [142.0, 2.0]   \n",
       "4    [18.0, 0.0, 17.0, 5.0, 4.0, 0.0, 1.0]           1.0  [23.0, 76.0]   \n",
       "..                                     ...           ...           ...   \n",
       "192  [30.0, 1.0, 10.0, 1.0, 0.0, 0.0, 0.0]           1.0   [1.0, 18.0]   \n",
       "193  [30.0, 1.0, 12.0, 3.0, 0.0, 0.0, 0.0]           1.0  [23.0, 76.0]   \n",
       "194  [30.0, 1.0, 15.0, 3.0, 0.0, 1.0, 2.0]           0.0  [23.0, 76.0]   \n",
       "195  [30.0, 1.0, 22.0, 8.0, 4.0, 2.0, 1.0]           0.0  [142.0, 2.0]   \n",
       "196  [30.0, 1.0, 24.0, 3.0, 4.0, 0.0, 0.0]           1.0  [33.0, 25.0]   \n",
       "\n",
       "                                    probability  prediction  \n",
       "0                                    [0.0, 1.0]         1.0  \n",
       "1      [0.6857142857142857, 0.3142857142857143]         0.0  \n",
       "2     [0.7532467532467533, 0.24675324675324675]         0.0  \n",
       "3    [0.9861111111111112, 0.013888888888888888]         0.0  \n",
       "4     [0.23232323232323232, 0.7676767676767676]         1.0  \n",
       "..                                          ...         ...  \n",
       "192   [0.05263157894736842, 0.9473684210526315]         1.0  \n",
       "193   [0.23232323232323232, 0.7676767676767676]         1.0  \n",
       "194   [0.23232323232323232, 0.7676767676767676]         1.0  \n",
       "195  [0.9861111111111112, 0.013888888888888888]         0.0  \n",
       "196   [0.5689655172413793, 0.43103448275862066]         0.0  \n",
       "\n",
       "[197 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Raw prediction\" for each possible label. The meaning of a \"raw\" prediction may vary between algorithms, but it intuitively gives a measure of confidence in each possible label (where larger = more confident).\n",
    "predictions.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c52dddf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_7b1196e5d3ed, depth=5, numNodes=37, numClasses=2, numFeatures=7\n",
      "  If (feature 2 <= 10.5)\n",
      "   If (feature 3 <= 5.5)\n",
      "    If (feature 5 in {2.0})\n",
      "     If (feature 4 in {0.0,2.0,3.0})\n",
      "      If (feature 3 <= 1.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 3 > 1.5)\n",
      "       Predict: 0.0\n",
      "     Else (feature 4 not in {0.0,2.0,3.0})\n",
      "      Predict: 1.0\n",
      "    Else (feature 5 not in {2.0})\n",
      "     If (feature 3 <= 1.5)\n",
      "      If (feature 4 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 4 not in {1.0})\n",
      "       Predict: 1.0\n",
      "     Else (feature 3 > 1.5)\n",
      "      Predict: 1.0\n",
      "   Else (feature 3 > 5.5)\n",
      "    If (feature 5 in {2.0})\n",
      "     If (feature 4 in {0.0,1.0,2.0,4.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 4 not in {0.0,1.0,2.0,4.0})\n",
      "      If (feature 0 <= 26.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 0 > 26.5)\n",
      "       Predict: 0.0\n",
      "    Else (feature 5 not in {2.0})\n",
      "     If (feature 0 <= 19.5)\n",
      "      If (feature 2 <= 8.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 2 > 8.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 0 > 19.5)\n",
      "      Predict: 1.0\n",
      "  Else (feature 2 > 10.5)\n",
      "   If (feature 3 <= 5.5)\n",
      "    If (feature 5 in {2.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 5 not in {2.0})\n",
      "     If (feature 2 <= 19.5)\n",
      "      Predict: 1.0\n",
      "     Else (feature 2 > 19.5)\n",
      "      Predict: 0.0\n",
      "   Else (feature 3 > 5.5)\n",
      "    If (feature 5 in {1.0,2.0})\n",
      "     If (feature 2 <= 14.5)\n",
      "      If (feature 3 <= 6.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 3 > 6.5)\n",
      "       Predict: 0.0\n",
      "     Else (feature 2 > 14.5)\n",
      "      Predict: 0.0\n",
      "    Else (feature 5 not in {1.0,2.0})\n",
      "     Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Decision Tree rules\n",
    "print(model.toDebugString)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15376414",
   "metadata": {},
   "source": [
    "### Evaluate the performance of a binary classification model\n",
    "\n",
    "**BinaryClassificationEvaluator:** This is an evaluator for binary classification, which expects two input columns: **raw prediction** and **label**.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "`rawPredictionCol=\"rawPrediction\"`: This parameter tells the evaluator to expect the column named \"rawPrediction\" in the dataset (typically predictions in this context) to hold the raw prediction values from the model.\n",
    "`labelCol=\"GradeNumeric\"`: This parameter tells the evaluator that the true labels for the binary classification task can be found in the \"GradeNumeric\" column of the dataset.\n",
    "evaluate() Method:\n",
    "\n",
    "`evaluator.evaluate(predictions)`: This is where the actual evaluation happens. The evaluate() method computes the metric (Area Under ROC, by default) for the predictions dataset using the true labels and raw predictions.\n",
    "\n",
    "**Area Under ROC:**\n",
    "\n",
    "The code calculates the Area Under the Receiver Operating Characteristic (ROC) curve, which is a metric used to evaluate the performance of binary classification models. The value of Area Under ROC (often abbreviated as AUC) ranges between 0 and 1. A value of 0.5 indicates no discriminative power (i.e., the model is as good as random guessing), while a value of 1.0 indicates perfect classification. A higher AUC indicates a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09bb820a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC: 0.7609565950273914\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"GradeNumeric\")\n",
    "area_under_roc = evaluator.evaluate(predictions)\n",
    "print(\"Area Under ROC:\", area_under_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436e1e14",
   "metadata": {},
   "source": [
    "When dealing with Spark's Machine Learning Library (MLlib), often one needs to evaluate the performance of a model, especially for classification tasks. In order to do that, you often use evaluators that require the prediction and actual label in a specific format.\n",
    "\n",
    "Convert 'predictions' DataFrame to an **Resilient Distributed Dataset(RDD)** of (prediction, label) tuples\" means that you need to transform the DataFrame (predictions) which contains predicted and actual values into a Resilient Distributed Dataset (RDD) that consists of tuples. Each tuple in this RDD contains two elements: the **predicted value** (often the first element) and the **actual label** (often the second element).\n",
    "\n",
    "Each tuple in this RDD contains two elements: the predicted value (often the first element) and the actual label (often the second element).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f331d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[283] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Convert 'predictions' DataFrame to an RDD of (prediction, label) tuples\n",
    "\n",
    "prediction_and_label = predictions.select(\"prediction\", \"GradeNumeric\").rdd.map(lambda row: (float(row[\"prediction\"]), float(row[\"GradeNumeric\"])))\n",
    "prediction_and_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e67d897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 1.0\n",
      "Prediction: 1.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 0.0\n",
      "Prediction: 0.0, Actual Label: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Using 'collect' to show the content of a RDD\n",
    "for pred, label in prediction_and_label.collect():\n",
    "    print(f\"Prediction: {pred}, Actual Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c45aad",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Where:\n",
    "\n",
    "- **TN (True Negative):** The number of actual negatives (0s) that were correctly predicted as negatives by the model.\n",
    "- **FP (False Positive):** The number of actual negatives (0s) that were incorrectly predicted as positives (1s) by the model.\n",
    "- **FN (False Negative):** The number of actual positives (1s) that were incorrectly predicted as negatives (0s) by the model.\n",
    "- **TP (True Positive):** The number of actual positives (1s) that were correctly predicted as positives by the model.\n",
    "\n",
    "\n",
    "###### Interpretation:\n",
    "\n",
    "**High values of TP and TN, along with low values of FP and FN, generally indicate a good model.**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6d8629e",
   "metadata": {},
   "source": [
    "          Predicted: \n",
    "          0     |   1\n",
    "-----------------------\n",
    "Actual: 0 |  TN    |   FP \n",
    "-----------------------\n",
    "Actual: 1 |  FN    |   TP \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eabb8a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MulticlassMetrics object to develop the Confusion Matrix\n",
    "metrics = MulticlassMetrics(prediction_and_label)\n",
    "confusion_matrix = metrics.confusionMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22dc9b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "DenseMatrix([[55., 68.],\n",
      "             [60., 49.]])\n"
     ]
    }
   ],
   "source": [
    "# Step 17:Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e7a700",
   "metadata": {},
   "source": [
    "### Using Scikit-learn package to get a detailed classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a55a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'predictions' DataFrame to a Pandas DataFrame\n",
    "predictions_pd = predictions.select(\"prediction\", \"GradeNumeric\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "951d111b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.45      0.46       123\n",
      "         1.0       0.42      0.45      0.43       109\n",
      "\n",
      "    accuracy                           0.45       232\n",
      "   macro avg       0.45      0.45      0.45       232\n",
      "weighted avg       0.45      0.45      0.45       232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 19: Calculate classification report\n",
    "report = classification_report(predictions_pd[\"GradeNumeric\"], predictions_pd[\"prediction\"])\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7078b68c",
   "metadata": {},
   "source": [
    "#### Plesae investigate the meaning of these metrics, as your homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcf0628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
