{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "957ef3c7",
   "metadata": {},
   "source": [
    "### Boston Housing\n",
    "\n",
    "Using the Boston House-price dataset available at the URL provided below, perform the following tasks using PySpark: \n",
    "\n",
    "1. Compute the pairwise correlations of the variables; \n",
    "2. Select the top three variables based on the pairwise correlations of the variables; \n",
    "3. Create a regression model using a polynomial function of degree two on the three selected variables. Use 70% of the data for training; \n",
    "4. Compute the R-Squared value of the model using the remaining 30% of the test data; and \n",
    "\n",
    "\n",
    "Import necessary libraries\n",
    "\n",
    "First, let's import the necessary libraries and then load the dataset from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d13647",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn # Visualising Library\n",
    "import pandas as pd # pandas for data manipulation and analysis. In this code we use it to show scatter plots.\n",
    "\n",
    "#Seaborn is a library for making statistical graphics in Python. \n",
    "#It builds on top of matplotlib and integrates closely with pandas data structures. \n",
    "#Seaborn helps you explore and understand your data.\n",
    "import seaborn as sb\n",
    "\n",
    "from matplotlib import pyplot as plt # We use matplotlib for create axe and figures to plot data \n",
    "from pyspark.ml.feature import VectorAssembler \n",
    "from pyspark.sql.types import DoubleType \n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import col # For use the column name of the dataframe in pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8dc486",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder. getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e192a0",
   "metadata": {},
   "source": [
    "### Import the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a53d35",
   "metadata": {},
   "source": [
    " #### Variables in order:\n",
    " \n",
    " * **CRIM**     per capita crime rate by town\n",
    " \n",
    " * **ZN**       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    " \n",
    " * **INDUS**    proportion of non-retail business acres per town\n",
    " \n",
    " * **CHAS**     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    " \n",
    " * **NOX**     nitric oxides concentration (parts per 10 million)\n",
    " \n",
    " * **RM**       average number of rooms per dwelling\n",
    " \n",
    " * **AGE**      proportion of owner-occupied units built prior to 1940\n",
    " \n",
    " * **DIS**      weighted distances to five Boston employment centres\n",
    " \n",
    " * **RAD**      index of accessibility to radial highways\n",
    " \n",
    " * **TAX**      full-value property-tax rate per $10,000\n",
    " \n",
    " * **PTRATIO**  pupil-teacher ratio by town\n",
    " \n",
    " * **B**        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    " \n",
    " * **LSTAT**    % lower status of the population\n",
    " \n",
    " * **MEDV**     Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603c19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here again we use infraschema becouse we need all columns to be double.\n",
    "boston_housing = spark.read.option('header', 'true').csv('boston.csv', inferSchema=True)\n",
    "boston_housing.show()\n",
    "print (boston_housing.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5328b1",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "\n",
    "Compute the pairwise correlations of the variables;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e4568",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_housing_pandas_dataframe = boston_housing.toPandas ()\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "sb.heatmap(boston_housing_pandas_dataframe.corr(), cmap=\"Blues\", annot=True, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604539b5",
   "metadata": {},
   "source": [
    "### Question 2:  \n",
    "\n",
    "Select the top three variables based on the pairwise correlations of the variables; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa45541",
   "metadata": {},
   "outputs": [],
   "source": [
    " fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "boston_housing_pandas_dataframe.plot.scatter(x='MEDV', y='LSTAT', ax=ax[0])\n",
    "boston_housing_pandas_dataframe.plot.scatter(x='MEDV', y='RM', ax=ax[1])\n",
    "boston_housing_pandas_dataframe.plot.scatter(x='MEDV', y='PTRATIO', ax=ax[2])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076dc18e",
   "metadata": {},
   "source": [
    "\n",
    "The correlation coefficient ranges from -1 to 1. When it is close to 1, it means that there is a strong positive correlation; for example, the median value (MED) tends to go up when the number of rooms (RM) goes up. When the coefficient is close to -1, it means that there is a strong negative correlation; the median value (MED) tends to go down when the percentage of the lower status of the population (LSTAT) goes up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab2347",
   "metadata": {},
   "source": [
    "### Section 3\n",
    "\n",
    "Create a regression model using a polynomial function of degree two on the three selected variables. Use 70% of the data for training;\n",
    "\n",
    "y=a*x^2+ b*x+ c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_housing = boston_housing.withColumn(\"LSTAT2\", col(\"LSTAT\") * col(\"LSTAT\"))\n",
    "boston_housing = boston_housing.withColumn (\"RM2\", col(\"RM\") * col(\"RM\"))\n",
    "#boston_housing = boston_housing.withColumn (\"RM2\", col(\"RM\") * col(\"RM\"))\n",
    "\n",
    "rmAssembler = VectorAssembler(inputCols = ['RM2', 'RM'] , outputCol='rm_features')\n",
    "lstatAssembler = VectorAssembler (inputCols = ['LSTAT2', 'LSTAT'] , outputCol= 'lstat_features')\n",
    "\n",
    "df_rm = rmAssembler.transform(boston_housing).select (['MEDV', 'rm_features'])\n",
    "df_lstat = lstatAssembler.transform(boston_housing).select(['MEDV', 'lstat_features'])\n",
    "\n",
    "df_rm.show()\n",
    "df_lstat.show()\n",
    "\n",
    "df_training_lstat, df_test_lstat = df_lstat.randomSplit([0.7, 0.3])\n",
    "df_training_rm, df_test_rm = df_rm.randomSplit([0.7, 0.3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9953db9a",
   "metadata": {},
   "source": [
    "### Create a regression model\n",
    "\n",
    "**maxiter** : It is the maximum number of iterations to perform before giving up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557b1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "pr = LinearRegression(featuresCol=\"lstat_features\", labelCol=\"MEDV\", maxIter=30)\n",
    "prModel = pr.fit(df_training_lstat)\n",
    "\n",
    "print(\"Coefficients: \" + str (prModel.coefficients))\n",
    "print(\"Intercept:\" + str (prModel.intercept)) # Describe Intercept\n",
    "\n",
    "print (\"R2:\", prModel.summary.r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e872e2d",
   "metadata": {},
   "source": [
    "$$ y=a \\times x^2+ b \\times x+ c $$\n",
    "\n",
    "\n",
    "\n",
    "$$MEDV = 0.055 \\times (LSTAT)^2 - 2.55 \\times (LSTAT) + 43.44$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddebcfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 50, 100)\n",
    "# From 0 to 50, create 100 numbers with equal distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52799d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = []\n",
    "for i in range(len(x)):\n",
    "    fx.append(prModel.coefficients[0]*x[i]*x[i] + prModel.coefficients[1]*x[i] + prModel.intercept)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d94b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, fx)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7568fa95",
   "metadata": {},
   "source": [
    "*R squared at 0.65 indicates that in our model, approximate 65% of the variability in \"MEDV\" can be explained using the model and the considered independent variable(s).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6125c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ef32ad",
   "metadata": {},
   "source": [
    "#### Compute the R-Squared value of the model using the remaining 30% of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e35c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_predictions = prModel.transform(df_test_lstat)\n",
    "pr_predictions.show()\n",
    "\n",
    "pr_predictions.select(\"prediction\", \"MEDV\", \"lstat_features\")\n",
    "\n",
    "pr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"MEDV\", metricName=\"r2\")\n",
    "\n",
    "print(\"R2 on test data:\", pr_evaluator.evaluate(pr_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c699fc5",
   "metadata": {},
   "source": [
    "Compare R2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3918cb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
